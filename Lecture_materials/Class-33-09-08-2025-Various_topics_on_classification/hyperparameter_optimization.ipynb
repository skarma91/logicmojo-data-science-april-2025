{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649b633",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameter Optimization for a Random Forest Classifier\n",
    "\n",
    "This notebook first gives the idea about cross-validation and then demonstrates different methods for hyperparameter tuning:\n",
    "\n",
    "1. Grid Search (scikit-learn)  \n",
    "2. Random Search (scikit-learn)  \n",
    "3. Bayesian Optimization (using Optuna)\n",
    "\n",
    "We use a real-life binary classification dataset (the breast cancer dataset from scikit-learn) and a Random Forest classifier.\n",
    "\n",
    "The techniques used in this notebook for hyper-parameter optimization can be used for other types of models as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c208532a",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd67d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 455, Test samples: 114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c34291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312a00d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Cross-Validation\n",
    "\n",
    "Cross-validation estimates model performance by splitting the training data into $k$ folds. For each fold:\n",
    "\n",
    "$$\n",
    "\\text{score} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{performance on fold } i\n",
    "$$\n",
    "\n",
    "We typically use $k=5$ or $k=10$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ccbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.96703297 0.98901099 0.92307692 0.93406593 0.95604396]\n",
      "Mean accuracy: 0.9538 ± 0.0235\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)   # default hyperparameters\n",
    "\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"Cross-validation accuracy scores:\", scores)\n",
    "print(\"Mean accuracy: {:.4f} ± {:.4f}\".format(scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446c40b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Grid Search (scikit-learn)\n",
    "\n",
    "Grid Search exhaustively explores a parameter grid. \n",
    "\n",
    "Denote parameters as $\\theta = \\{n_{\\text{estimators}}, \\max\\_depth, \\ldots\\}$. We evaluate:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\max_{\\theta \\in \\Theta} \\text{CVScore}(\\theta)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2192227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best CV accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42), # we can use other model as well\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',   # we can use other metrics like 'f1', 'roc_auc', etc.\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(f\"Best CV accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a98a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(min_samples_split=5, n_estimators=50, random_state=42)\n",
      "Test set accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "print(best_rf)\n",
    "test_acc = best_rf.score(X_test, y_test)\n",
    "print(f\"Test set accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45fbcc",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Random Search (scikit-learn)\n",
    "\n",
    "Random Search samples parameter combinations randomly—more efficient when the grid is large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aae6bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters (Random Search): {'max_depth': 11, 'min_samples_split': 2, 'n_estimators': 161}\n",
      "Best CV accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None] + list(range(3, 15)),\n",
    "    'min_samples_split': randint(2, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best parameters (Random Search):\", random_search.best_params_)\n",
    "print(f\"Best CV accuracy: {random_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85efc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Random Search): 0.9561\n"
     ]
    }
   ],
   "source": [
    "best_rf_rand = random_search.best_estimator_\n",
    "test_acc_rand = best_rf_rand.score(X_test, y_test)\n",
    "print(f\"Test set accuracy (Random Search): {test_acc_rand:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a99c6",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Bayesian Optimization (Optuna)\n",
    "\n",
    "These methods model the search process more intelligently. We'll demonstrate Optuna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36818bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (1.16.4)\n",
      "Requirement already satisfied: colorlog in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (2.0.42)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\sourav karmakar\\desktop\\work\\logicmojo\\logicmojo-data-science-april-2025\\.venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07f44f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sourav Karmakar\\Desktop\\Work\\LogicMojo\\logicmojo-data-science-april-2025\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-08-09 12:19:24,723] A new study created in memory with name: no-name-0e614e66-6ab0-4709-bb17-3bb1183fa658\n",
      "[I 2025-08-09 12:19:26,386] Trial 0 finished with value: 0.9538461538461538 and parameters: {'n_estimators': 162, 'max_depth': 13, 'min_samples_split': 5}. Best is trial 0 with value: 0.9538461538461538.\n",
      "[I 2025-08-09 12:19:27,118] Trial 1 finished with value: 0.9560439560439562 and parameters: {'n_estimators': 77, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 1 with value: 0.9560439560439562.\n",
      "[I 2025-08-09 12:19:28,914] Trial 2 finished with value: 0.953846153846154 and parameters: {'n_estimators': 198, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 1 with value: 0.9560439560439562.\n",
      "[I 2025-08-09 12:19:29,696] Trial 3 finished with value: 0.9582417582417584 and parameters: {'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 6}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:31,259] Trial 4 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 184, 'max_depth': 11, 'min_samples_split': 8}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:32,106] Trial 5 finished with value: 0.9560439560439562 and parameters: {'n_estimators': 94, 'max_depth': 9, 'min_samples_split': 5}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:33,642] Trial 6 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 196, 'max_depth': 3, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:34,856] Trial 7 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 137, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:36,202] Trial 8 finished with value: 0.953846153846154 and parameters: {'n_estimators': 153, 'max_depth': 11, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:37,724] Trial 9 finished with value: 0.953846153846154 and parameters: {'n_estimators': 175, 'max_depth': 12, 'min_samples_split': 6}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:38,238] Trial 10 finished with value: 0.9494505494505496 and parameters: {'n_estimators': 54, 'max_depth': 6, 'min_samples_split': 10}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:39,052] Trial 11 finished with value: 0.953846153846154 and parameters: {'n_estimators': 90, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:39,775] Trial 12 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 82, 'max_depth': 13, 'min_samples_split': 2}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:40,780] Trial 13 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 113, 'max_depth': 6, 'min_samples_split': 3}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:41,418] Trial 14 finished with value: 0.9538461538461538 and parameters: {'n_estimators': 71, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:42,490] Trial 15 finished with value: 0.9582417582417584 and parameters: {'n_estimators': 120, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:43,530] Trial 16 finished with value: 0.953846153846154 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:44,673] Trial 17 finished with value: 0.9538461538461538 and parameters: {'n_estimators': 130, 'max_depth': 13, 'min_samples_split': 5}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:45,582] Trial 18 finished with value: 0.9494505494505496 and parameters: {'n_estimators': 103, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:46,094] Trial 19 finished with value: 0.9560439560439562 and parameters: {'n_estimators': 53, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:47,336] Trial 20 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 138, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:47,990] Trial 21 finished with value: 0.953846153846154 and parameters: {'n_estimators': 73, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:48,609] Trial 22 finished with value: 0.9582417582417584 and parameters: {'n_estimators': 68, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:49,240] Trial 23 finished with value: 0.953846153846154 and parameters: {'n_estimators': 66, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:50,165] Trial 24 finished with value: 0.9516483516483518 and parameters: {'n_estimators': 103, 'max_depth': 14, 'min_samples_split': 2}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:51,222] Trial 25 finished with value: 0.953846153846154 and parameters: {'n_estimators': 116, 'max_depth': 11, 'min_samples_split': 5}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:51,783] Trial 26 finished with value: 0.9582417582417584 and parameters: {'n_estimators': 62, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:52,571] Trial 27 finished with value: 0.9582417582417584 and parameters: {'n_estimators': 87, 'max_depth': 13, 'min_samples_split': 6}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:53,414] Trial 28 finished with value: 0.953846153846154 and parameters: {'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 3 with value: 0.9582417582417584.\n",
      "[I 2025-08-09 12:19:54,737] Trial 29 finished with value: 0.9538461538461538 and parameters: {'n_estimators': 152, 'max_depth': 13, 'min_samples_split': 5}. Best is trial 3 with value: 0.9582417582417584.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna best params: {'n_estimators': 87, 'max_depth': 11, 'min_samples_split': 6}\n",
      "Optuna best CV accuracy: 0.9582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Optuna best params:\", study.best_params)\n",
    "print(f\"Optuna best CV accuracy: {study.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da2518b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy (Optuna): 0.9561\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optuna_rf = RandomForestClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=42\n",
    ")\n",
    "optuna_rf.fit(X_train, y_train)\n",
    "optuna_test_acc = optuna_rf.score(X_test, y_test)\n",
    "print(f\"Test set accuracy (Optuna): {optuna_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1484f0cd",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Summary and Comparison\n",
    "\n",
    "The following numbers may vary due to the inherent randomness of data splitting, model training, cross validation and optimization.\n",
    "\n",
    "| Method             | Best CV Accuracy | Test Accuracy |\n",
    "|--------------------|------------------|---------------|\n",
    "| Grid Search        | 0.9582           |0.9474         |\n",
    "| Random Search      | 0.9604           |0.9561         |\n",
    "| Optuna (Bayesian)  | 0.9582           |0.9561         |\n",
    "\n",
    "For large datasets and large hyper-parameter space, usually random search / bayesian search performs best. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f7efd",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading models in sklearn using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50efe980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33994340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_rf_model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "# joblib.dump(model, \"path\")\n",
    "\n",
    "joblib.dump(optuna_rf, 'best_rf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c66e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=11, min_samples_split=6, n_estimators=87,\n",
      "                       random_state=42)\n",
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "# joblib.load(\"model path\")\n",
    "\n",
    "loaded_model = joblib.load(\"best_rf_model.joblib\")\n",
    "\n",
    "print(loaded_model)\n",
    "\n",
    "print(loaded_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da6309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
